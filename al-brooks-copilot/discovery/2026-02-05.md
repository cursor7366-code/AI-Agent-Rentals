# Discovery Report — 2026-02-05

## Summary
- 8 new items evaluated
- 0 promoted to higher priority
- 3 worth adding to radar (1 MEDIUM, 2 WATCHING)
- 3 radar items checked (all stable)

---

## New Discoveries

### 1. flow-forecast
- **Source**: GitHub (AIStream-Peelout/flow-forecast)
- **Category**: Regime Inference / Signal Extraction
- **Stars**: 2,273
- **What it does**: Deep learning PyTorch library for time series forecasting, classification, and anomaly detection
- **Why interesting**: Mature library with anomaly detection built-in. Anomaly detection could be repurposed for regime change detection — unusual market behavior = potential regime shift.
- **How you'd use it**: Feed 5-min OHLC bars → detect anomalies in price action → flag regime transitions. Could complement TimesFM by catching "something weird is happening" moments.
- **Maturity**: Well-maintained, 2.2k stars, active development
- **Initial verdict**: MEDIUM — worth benchmarking alongside TimesFM for regime inference
- **Link**: https://github.com/AIStream-Peelout/flow-forecast

### 2. mHC-iTransformer  
- **Source**: GitHub (2308087369/mHC-iTransformer)
- **Category**: Regime Inference
- **Stars**: 27
- **What it does**: Time series SOTA based on DeepSeek's mHC architecture — replaces residual links in iTransformer
- **Why interesting**: Claims new SOTA. DeepSeek's mHC pattern (mixture of depths) is novel. If this holds up, it's a more efficient architecture for time series.
- **How you'd use it**: Same as TimesFM/Lag-Llama — OHLC → regime probabilities. Smaller model could mean faster inference.
- **Maturity**: Very new (27 stars), needs verification
- **Initial verdict**: WATCHING — too early but architecture is interesting. Check back in 2 weeks.
- **Link**: https://github.com/2308087369/mHC-iTransformer

### 3. Lexoid
- **Source**: GitHub (oidlabs-com/Lexoid)
- **Category**: Vision Pipeline
- **Stars**: 89
- **What it does**: Multimodal document parser for "high quality data understanding and extraction"
- **Why interesting**: Specifically built for structured extraction from complex documents. Could handle the Al Brooks slides better than generic OCR.
- **How you'd use it**: Feed slide images → extract structured chart data, annotations, text. Could be the "understanding" layer before YOLO detects specific elements.
- **Maturity**: 89 stars, newer project, active
- **Initial verdict**: WATCHING — worth a deeper look when Vision Pipeline becomes active priority
- **Link**: https://github.com/oidlabs-com/Lexoid

### 4. PyMuPDF
- **Source**: GitHub (pymupdf/PyMuPDF)
- **Category**: Vision Pipeline
- **Stars**: 8,993
- **What it does**: High performance PDF data extraction, analysis, conversion
- **Why interesting**: Already on radar implicitly (it's what many tools use under the hood). If the slides are in PDF format, this is the extraction layer.
- **How you'd use it**: PDF → images → YOLO pipeline. PyMuPDF handles the PDF parsing reliably.
- **Maturity**: Very mature, 9k stars, actively maintained
- **Initial verdict**: Already assumed in stack — no action needed
- **Link**: https://github.com/pymupdf/PyMuPDF

### 5. Qwen-VL Multimodal RAG Demo
- **Source**: GitHub (holisticon/multimodal-rag-demo)
- **Category**: Retrieval / Vision
- **Stars**: 4
- **What it does**: Multimodal RAG using Qwen3-VL embedding + reranker
- **Why interesting**: Combines vision and retrieval — could index slides as images AND text, search across both.
- **How you'd use it**: Index 12k slides with their visual content, retrieve by "show me a slide with a failed breakout" (visual similarity + text).
- **Maturity**: Too early (4 stars), but the pattern is valuable
- **Initial verdict**: REJECT as tool, but note the pattern — Qwen-VL for multimodal retrieval is emerging
- **Link**: https://github.com/holisticon/multimodal-rag-demo

### 6. MistralOCR Document Extraction
- **Source**: GitHub (AkshayG999/MistralOCR)
- **Category**: Vision Pipeline
- **Stars**: 10
- **What it does**: Transforms documents into structured data using Mistral AI's OCR
- **Why interesting**: Structured output from OCR — not just text, but parsed fields. Relevant to Mistral OCR-3 we identified yesterday.
- **Maturity**: Early (10 stars)
- **Initial verdict**: WATCHING — confirms Mistral OCR direction is worth tracking
- **Link**: https://github.com/AkshayG999/MistralOCR

### 7. MiiFlow Agent
- **Source**: GitHub (MiiFlow/miiflow-agent)
- **Category**: Decision Engine / Agent Framework
- **Stars**: 11
- **What it does**: Lightweight Python SDK for LLMs — unified API across 9 providers, ReAct & Plan-Execute agents, native tool calling, structured outputs
- **Why interesting**: "Lightweight" is appealing vs. heavy frameworks. Native structured output + tool calling = decision engine primitives.
- **How you'd use it**: Could be the thin orchestration layer between LLM and your tools (retrieval, regime inference, etc.)
- **Maturity**: Very new (11 stars)
- **Initial verdict**: REJECT — too early, and Instructor already solves structured output better
- **Link**: https://github.com/MiiFlow/miiflow-agent

### 8. Prompture
- **Source**: GitHub (jhd3197/Prompture)
- **Category**: Decision Engine
- **Stars**: 8
- **What it does**: API-first library for structured JSON output, schema validation, comparative model testing
- **Why interesting**: Model comparison built-in — test same prompt across models to find best one for your task.
- **Maturity**: Early (8 stars)
- **Initial verdict**: REJECT — Instructor does this better with more maturity
- **Link**: https://github.com/jhd3197/Prompture

---

## Radar Monitoring

### TradingAgents ⭐29,279 (was 29,200)
- **Status**: Still very active — pushed yesterday, updated today
- **Changes**: +79 stars in 24h, 225 open issues (healthy activity)
- **Verdict**: ➡️ NO CHANGE — remains top SHORT priority for Decision Engine

### LightRAG ⭐27,888 (no change)
- **Status**: Last push Jan 29 (1 week ago), 189 open issues
- **Changes**: Slight slowdown in commits, but stars holding steady
- **Verdict**: ➡️ NO CHANGE — still solid for retrieval upgrade when needed

### Instructor ⭐12,307
- **Status**: Active — pushed Feb 3, only 21 open issues (very clean)
- **Changes**: Healthy issue:star ratio (0.17%), well-maintained
- **Verdict**: ➡️ NO CHANGE — remains NOW priority. Low issue count is a good sign.

---

## Synthesis & Analysis

### Tool Combinations Worth Noting

1. **flow-forecast + TimesFM**: Different approaches to the same problem (regime inference). flow-forecast brings anomaly detection, TimesFM brings foundation model priors. Could run both:
   - TimesFM → "trending/ranging/breakout" classification
   - flow-forecast → "anomaly detected, confidence dropping" early warning
   - Combined = more robust regime inference

2. **Lexoid + PyMuPDF + YOLO**: Three-layer vision stack:
   - PyMuPDF extracts images from PDF
   - Lexoid understands document structure / annotations
   - YOLO detects specific chart elements (bars, patterns)
   - This is likely the architecture for vision pipeline

3. **Qwen-VL Embeddings + LightRAG**: The multimodal RAG demo shows Qwen-VL can embed images. If LightRAG adopts this, retrieval becomes multimodal — "find slides that LOOK like this pattern."

### Architectural Patterns Emerging

**Pattern: Specialized Models > General Models for Domain Tasks**
- Seeing more "small model trained on X domain" vs "use GPT-4 for everything"
- mHC-iTransformer, flow-forecast, TimesFM all target time series specifically
- **Bet**: Domain-specific models will outperform general LLMs for regime inference

**Pattern: Structured Output as a Primitive**
- Instructor, Prompture, MiiFlow all compete on "guaranteed JSON from LLM"
- This is becoming table stakes, not a feature
- **Bet**: Instructor wins this space due to maturity; don't shop around

**Pattern: Vision Pipeline Convergence**
- OCR → Multimodal VLM → Structured extraction
- Mistral OCR-3, Lexoid, Qwen-VL all point same direction
- **Bet**: By Q2, a "PDF → structured data" tool will emerge that handles charts natively

### What Could We Build?

**Idea: Anomaly-Triggered Regime Reassessment**
- Normal flow: TimesFM runs regime inference on schedule
- Enhancement: flow-forecast monitors for anomalies continuously
- When anomaly detected → trigger immediate TimesFM reassessment
- Result: Faster regime detection without constant expensive inference

**Idea: Visual Pattern Retrieval**
- Current: Text search over summaries
- Enhanced: Qwen-VL embeds slide images, search by visual similarity
- Query: "Show me slides where price looks like this" (screenshot input)
- Requires: LightRAG + multimodal embeddings

---

## Recommendations

### This Week
1. **Instructor** — Still the pick for structured output. Implement it.
2. **TradingAgents** — Deep dive this week. 29k stars, very active, matches exactly what you're building.

### Next 2 Weeks
1. **flow-forecast** — Benchmark for anomaly detection alongside TimesFM
2. **Lexoid** — Evaluate when vision pipeline starts

### No Action Needed
- LightRAG, Instructor, TradingAgents all stable — no priority changes
- New discoveries today are mostly WATCHING or REJECT

---

## Notes

- Quiet day for HIGH-priority discoveries
- The mHC-iTransformer is interesting architecturally but too early
- Vision pipeline tools are maturing — when that module activates, Lexoid + Mistral OCR-3 are the top candidates
- Structured output space is solved (Instructor) — stop looking at alternatives
